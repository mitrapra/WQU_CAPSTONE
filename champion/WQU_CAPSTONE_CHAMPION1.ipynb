{"cells":[{"source":"# Install the latest version of the colorama package to enable colorful terminal text, enhancing readability\n!pip install -U colorama\n\n# Install the empyrical package to compute various financial risk and performance metrics, useful for quantitative finance\n!pip install empyrical\n\n# Install a specific version (1.4.3) of the bayesian-optimization package, which is used for optimizing hyperparameters in machine learning models\n!pip install bayesian-optimization==1.4.3\n\n# Install the pmdarima package, a convenient tool for auto-fitting ARIMA models, which are widely used in time series forecasting\n!pip install pmdarima\n\n# Install a specific version (2.14.0) of tensorflow, a powerful library for machine learning and neural networks, to ensure compatibility with certain features or other libraries\n!pip install tensorflow==2.16.1","metadata":{"executionCancelledAt":null,"executionTime":24790,"lastExecutedAt":1716127239181,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install the latest version of the colorama package to enable colorful terminal text, enhancing readability\n!pip install -U colorama\n\n# Install the empyrical package to compute various financial risk and performance metrics, useful for quantitative finance\n!pip install empyrical\n\n# Install a specific version (1.4.3) of the bayesian-optimization package, which is used for optimizing hyperparameters in machine learning models\n!pip install bayesian-optimization==1.4.3\n\n# Install the pmdarima package, a convenient tool for auto-fitting ARIMA models, which are widely used in time series forecasting\n!pip install pmdarima\n\n# Install a specific version (2.14.0) of tensorflow, a powerful library for machine learning and neural networks, to ensure compatibility with certain features or other libraries\n!pip install tensorflow==2.16.1","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"eb5caf02-6f80-4c2d-a7ef-8103426f08e1","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: colorama in /home/repl/.local/lib/python3.10/site-packages (0.4.6)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: empyrical in /home/repl/.local/lib/python3.10/site-packages (0.5.5)\nRequirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from empyrical) (1.26.4)\nRequirement already satisfied: pandas>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from empyrical) (2.2.1)\nRequirement already satisfied: scipy>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from empyrical) (1.11.4)\nRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.16.1->empyrical) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.16.1->empyrical) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.16.1->empyrical) (2024.1)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical) (5.1.0)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical) (2.31.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=0.16.1->empyrical) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical) (2024.2.2)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: bayesian-optimization==1.4.3 in /home/repl/.local/lib/python3.10/site-packages (1.4.3)\nRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.26.4)\nRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.4.3) (1.4.1.post1)\nRequirement already satisfied: colorama>=0.4.6 in /home/repl/.local/lib/python3.10/site-packages (from bayesian-optimization==1.4.3) (0.4.6)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.3) (3.3.0)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pmdarima in /home/repl/.local/lib/python3.10/site-packages (2.0.4)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.3.2)\nRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (0.29.37)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.26.4)\nRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.2.1)\nRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.4.1.post1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.11.4)\nRequirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (0.14.1)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.26.18)\nRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (69.2.0)\nRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (24.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2024.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->pmdarima) (3.3.0)\nRequirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.4->statsmodels>=0.13.2->pmdarima) (1.16.0)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: tensorflow==2.16.1 in /home/repl/.local/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.7)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.25.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.31.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (69.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.16.1) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.10.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.62.1)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.1.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.36.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.43.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.7.1)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.0.7)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.10.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.2.2)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n"}]},{"source":"# The following line of code is used to install the 'ipython-extensions' package using pip, Python's package installer. \n# The 'ipython-extensions' package contains a collection of extensions for IPython, which enhance its functionality and usability. \n# These extensions can include new magic commands, additional configuration options, and improved integration with other tools and libraries. \n# Installing this package can significantly enhance the interactive Python programming experience, especially within Jupyter notebooks where IPython is commonly used.\n\n!pip install ipython-extensions","metadata":{"executionCancelledAt":null,"executionTime":6011,"lastExecutedAt":1716127254474,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# The following line of code is used to install the 'ipython-extensions' package using pip, Python's package installer. \n# The 'ipython-extensions' package contains a collection of extensions for IPython, which enhance its functionality and usability. \n# These extensions can include new magic commands, additional configuration options, and improved integration with other tools and libraries. \n# Installing this package can significantly enhance the interactive Python programming experience, especially within Jupyter notebooks where IPython is commonly used.\n\n!pip install ipython-extensions","outputsMetadata":{"0":{"height":80,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"e7af6e60-9690-4cac-82c9-6febd3e48032","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting ipython-extensions\n  Downloading ipython-extensions-0.2.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ipython-extensions\n  Building wheel for ipython-extensions (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ipython-extensions: filename=ipython_extensions-0.2-py3-none-any.whl size=4806 sha256=3ba97854e13eeaf9209b1b2e17afd3ff99b8218954bbd85c423ebf5c5082582c\n  Stored in directory: /home/repl/.cache/pip/wheels/e6/b8/8c/937067faedc50d949c55c159058f7ed0fbbc4b76fb689a7b99\nSuccessfully built ipython-extensions\nInstalling collected packages: ipython-extensions\nSuccessfully installed ipython-extensions-0.2\n"}],"execution_count":3},{"source":"# Import the bayes_opt library\n# This library is used for Bayesian Optimization which is a method of finding the maximum or minimum of an objective function\n# that is expensive to evaluate. It's often used for hyperparameter tuning in machine learning models.\nimport bayes_opt","metadata":{"executionCancelledAt":null,"executionTime":1171,"lastExecutedAt":1716127245124,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the bayes_opt library\n# This library is used for Bayesian Optimization which is a method of finding the maximum or minimum of an objective function\n# that is expensive to evaluate. It's often used for hyperparameter tuning in machine learning models.\nimport bayes_opt"},"id":"880cc642-1220-42f8-84f1-3b0bc463ac6f","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Import the MarketDataEngineer class from the MarketDataEngineer module located in the champion.source.data package.\n# This class is likely responsible for engineering or processing market data for further analysis or modeling.\n# It could be used to clean, normalize, or aggregate market data before it's used in financial models or analyses.\nfrom champion.source.data.MarketDataEngineer import MarketDataEngineer\n\n# Import all functions and classes from the _util module located in the champion.source.util package.\n# This could include various utility functions or classes that are used across the project for different purposes such as data manipulation, logging, etc.\n# Utility modules often contain helper functions that simplify common tasks, making the main code cleaner and more readable.\nfrom champion.source.util._util import *\n\n# Import all functions and classes from the _trainModels module located in the champion.pipeline package.\n# This module is likely responsible for training machine learning models. It could contain functions or classes to train, evaluate, and save models.\n# Training models involves feeding data into algorithms to allow them to learn and make predictions. This module likely encapsulates that process.\nfrom champion.pipeline._trainModels import *\n\n# Import all functions and classes from the _evaluateModels module located in the champion.pipeline package.\n# This module is probably dedicated to evaluating the performance of trained models. It might include functions for calculating accuracy, precision, recall, etc.\n# Evaluating models is crucial to understand their effectiveness and to decide which model performs best for a given dataset or problem.\nfrom champion.pipeline._evaluateModels import *\n\n# Import all functions and classes from the _causalInference module located in the champion.pipeline package.\n# This module is likely focused on causal inference methods, which are used to determine causality rather than just correlations between variables.\n# Causal inference is important in many fields, including economics, epidemiology, and social sciences, to understand the impact of interventions.\nfrom champion.pipeline._causalInference import *\n\n# Import all functions and classes from the _stressBacktest module located in the champion.pipeline package.\n# This module is probably used for stress testing and backtesting models. Stress testing involves testing models under extreme conditions,\n# while backtesting is the process of testing a predictive model on historical data.\n# These techniques are essential for assessing the robustness and reliability of financial models before they are deployed.\nfrom champion.pipeline._stressBacktest import *","metadata":{"executionCancelledAt":null,"executionTime":3947,"lastExecutedAt":1716127265035,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the MarketDataEngineer class from the MarketDataEngineer module located in the champion.source.data package.\n# This class is likely responsible for engineering or processing market data for further analysis or modeling.\n# It could be used to clean, normalize, or aggregate market data before it's used in financial models or analyses.\nfrom champion.source.data.MarketDataEngineer import MarketDataEngineer\n\n# Import all functions and classes from the _util module located in the champion.source.util package.\n# This could include various utility functions or classes that are used across the project for different purposes such as data manipulation, logging, etc.\n# Utility modules often contain helper functions that simplify common tasks, making the main code cleaner and more readable.\nfrom champion.source.util._util import *\n\n# Import all functions and classes from the _trainModels module located in the champion.pipeline package.\n# This module is likely responsible for training machine learning models. It could contain functions or classes to train, evaluate, and save models.\n# Training models involves feeding data into algorithms to allow them to learn and make predictions. This module likely encapsulates that process.\nfrom champion.pipeline._trainModels import *\n\n# Import all functions and classes from the _evaluateModels module located in the champion.pipeline package.\n# This module is probably dedicated to evaluating the performance of trained models. It might include functions for calculating accuracy, precision, recall, etc.\n# Evaluating models is crucial to understand their effectiveness and to decide which model performs best for a given dataset or problem.\nfrom champion.pipeline._evaluateModels import *\n\n# Import all functions and classes from the _causalInference module located in the champion.pipeline package.\n# This module is likely focused on causal inference methods, which are used to determine causality rather than just correlations between variables.\n# Causal inference is important in many fields, including economics, epidemiology, and social sciences, to understand the impact of interventions.\nfrom champion.pipeline._causalInference import *\n\n# Import all functions and classes from the _stressBacktest module located in the champion.pipeline package.\n# This module is probably used for stress testing and backtesting models. Stress testing involves testing models under extreme conditions,\n# while backtesting is the process of testing a predictive model on historical data.\n# These techniques are essential for assessing the robustness and reliability of financial models before they are deployed.\nfrom champion.pipeline._stressBacktest import *","outputsMetadata":{"0":{"height":227,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"a84f7a57-d308-4abb-a4a5-66cd24fc0f9c","outputs":[{"output_type":"stream","name":"stderr","text":"2024-05-19 14:01:02.025272: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-05-19 14:01:02.028468: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-05-19 14:01:02.064057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-05-19 14:01:03.054766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"}],"execution_count":4},{"source":"# Call the dir_management function to manage directories\n# This could involve creating necessary directories for output, logs, or intermediate data storage\ndir_management()\n\n# Initialize a timer to measure the duration of the data loading process\nstart = time.time()\n\n# Create an instance of the MarketDataEngineer class\n# This object is responsible for handling market data, possibly including cleaning, transforming, and loading operations\nloader = MarketDataEngineer()\n\n# Execute the ETL (Extract, Transform, Load) process using the loader instance\n# This process extracts data from a source, transforms it into a suitable format, and loads it into a destination for further use\nloader.etl_process()\n\n# Calculate the time taken for the ETL process to complete\n# This is done by subtracting the start time from the current time\netl_load_time = time.time() - start","metadata":{"executionCancelledAt":null,"executionTime":2385,"lastExecutedAt":1716096176387,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Call the dir_management function to manage directories\n# This could involve creating necessary directories for output, logs, or intermediate data storage\ndir_management()\n\n# Initialize a timer to measure the duration of the data loading process\nstart = time.time()\n\n# Create an instance of the MarketDataEngineer class\n# This object is responsible for handling market data, possibly including cleaning, transforming, and loading operations\nloader = MarketDataEngineer()\n\n# Execute the ETL (Extract, Transform, Load) process using the loader instance\n# This process extracts data from a source, transforms it into a suitable format, and loads it into a destination for further use\nloader.etl_process()\n\n# Calculate the time taken for the ETL process to complete\n# This is done by subtracting the start time from the current time\netl_load_time = time.time() - start","outputsMetadata":{"0":{"height":59,"type":"stream"},"1":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"4cefbb43-3d50-4e3a-97b3-7a424896afd3","outputs":[],"execution_count":4},{"source":"# Start measuring the time to track how long the training process takes\nstart_time = time.time()\n\n# Initialize the Logistic Regression model\nlogistic_regression_model = Logistic_Regression()\n\n# Train the Logistic Regression model using the available data\nlogistic_regression_model.model_training()\n\n# Save the trained Logistic Regression model to a file for future use\nlogistic_regression_model.save_model()\n\n# Calculate the duration of the training process by subtracting the start time from the current time\nLR_training_duration = time.time() - start_time","metadata":{"executionCancelledAt":null,"executionTime":101,"lastExecutedAt":1716095596988,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start measuring the time to track how long the training process takes\nstart_time = time.time()\n\n# Initialize the Logistic Regression model\nlogistic_regression_model = Logistic_Regression()\n\n# Train the Logistic Regression model using the available data\nlogistic_regression_model.model_training()\n\n# Save the trained Logistic Regression model to a file for future use\nlogistic_regression_model.save_model()\n\n# Calculate the duration of the training process by subtracting the start time from the current time\nLR_training_duration = time.time() - start_time"},"cell_type":"code","id":"bdd87f36-3883-4916-a70c-b0b3ddb42c9b","outputs":[],"execution_count":8},{"source":"# Start measuring the time to track how long the ARIMA model training process takes\ntraining_start_time = time.time()\n\n# Initialize the ARIMA model for time-series forecasting\ntime_series_model = ARIMA()\n\n# Train the ARIMA model using the available time-series data\ntime_series_model.model_training()\n\n# Save the trained ARIMA model to a file for future use or deployment\ntime_series_model.save_model()\n\n# Calculate the duration of the ARIMA model training process\n# This is done by subtracting the start time from the current time\narima_training_duration = time.time() - training_start_time","metadata":{"executionCancelledAt":null,"executionTime":4218,"lastExecutedAt":1716091975014,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start measuring the time to track how long the ARIMA model training process takes\ntraining_start_time = time.time()\n\n# Initialize the ARIMA model for time-series forecasting\ntime_series_model = ARIMA()\n\n# Train the ARIMA model using the available time-series data\ntime_series_model.model_training()\n\n# Save the trained ARIMA model to a file for future use or deployment\ntime_series_model.save_model()\n\n# Calculate the duration of the ARIMA model training process\n# This is done by subtracting the start time from the current time\narima_training_duration = time.time() - training_start_time","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"outputsMetadata":{"0":{"height":206,"type":"stream"}}},"cell_type":"code","id":"aaa5eea3-a34d-49f6-adf2-966473cb837e","outputs":[],"execution_count":6},{"source":"# Start timing the Random Forest training process to measure how long it takes\nstart_time_random_forest = time.time()\n\n# Initialize the Random Forest model\n# This step creates an instance of the Random Forest algorithm to be trained with the dataset\nrandom_forest_model = RandomForest()\n\n# Train the Random Forest model with the provided dataset\n# This involves fitting the model to the data, allowing it to learn the patterns in the data\nrandom_forest_model.model_training()\n\n# Save the trained Random Forest model to a file\n# This allows the model to be reused in the future without needing to retrain it\nrandom_forest_model.save_model()\n\n# Calculate the training duration for the Random Forest model\n# This is done by subtracting the start time from the current time to get the total training time\nrandom_forest_training_duration = time.time() - start_time_random_forest","metadata":{"executionCancelledAt":null,"executionTime":43868,"lastExecutedAt":1715669083366,"lastExecutedByKernel":"da83825d-af40-40cf-ad37-4c6c50e3ba6c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start timing the Random Forest training process to measure how long it takes\nstart_time_random_forest = time.time()\n\n# Initialize the Random Forest model\n# This step creates an instance of the Random Forest algorithm to be trained with the dataset\nrandom_forest_model = RandomForest()\n\n# Train the Random Forest model with the provided dataset\n# This involves fitting the model to the data, allowing it to learn the patterns in the data\nrandom_forest_model.model_training()\n\n# Save the trained Random Forest model to a file\n# This allows the model to be reused in the future without needing to retrain it\nrandom_forest_model.save_model()\n\n# Calculate the training duration for the Random Forest model\n# This is done by subtracting the start time from the current time to get the total training time\nrandom_forest_training_duration = time.time() - start_time_random_forest","outputsMetadata":{"0":{"height":206,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"44740c5f-36bf-4bc4-9480-294ff6a667b3","outputs":[],"execution_count":21},{"source":"# 4. Boosting Models Training and Saving\n\n# Start timing the LightGBM model training process\nlightgbm_start_time = time.time()\n\n# Initialize the LightGBM model\n# This creates an instance of the LightGBM algorithm to be trained with the dataset\nlightgbm_boosting_model = LightGBM()\n\n# Train the LightGBM model with the provided dataset\n# This involves fitting the model to the data, allowing it to learn from the patterns\nlightgbm_boosting_model.model_training()\n\n# Save the trained LightGBM model to a file\n# This step is crucial for deploying the model in production without retraining\nlightgbm_boosting_model.save_model()\n\n# Calculate the training duration for the LightGBM model\n# This is achieved by subtracting the start time from the current time\nlightgbm_training_duration = time.time() - lightgbm_start_time\n\n# Start timing the XGBoost model training process\nxgboost_start_time = time.time()\n\n# Initialize the XGBoost model\n# This step creates an instance of the XGBoost algorithm for training\nxgboost_boosting_model = XGBoost()\n\n# Train the XGBoost model with the dataset\n# The training process allows the model to learn the patterns within the data\nxgboost_boosting_model.model_training()\n\n# Save the trained XGBoost model to a file\n# Saving the model enables future use without the need for retraining\nxgboost_boosting_model.save_model()\n\n# Calculate the training duration for the XGBoost model\n# The duration is calculated by subtracting the start time from the current time\nxgboost_training_duration = time.time() - xgboost_start_time","metadata":{"executionCancelledAt":null,"executionTime":20676016,"lastExecutedAt":1715689850412,"lastExecutedByKernel":"da83825d-af40-40cf-ad37-4c6c50e3ba6c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 4. Boosting Models Training and Saving\n\n# Start timing the LightGBM model training process\nlightgbm_start_time = time.time()\n\n# Initialize the LightGBM model\n# This creates an instance of the LightGBM algorithm to be trained with the dataset\nlightgbm_boosting_model = LightGBM()\n\n# Train the LightGBM model with the provided dataset\n# This involves fitting the model to the data, allowing it to learn from the patterns\nlightgbm_boosting_model.model_training()\n\n# Save the trained LightGBM model to a file\n# This step is crucial for deploying the model in production without retraining\nlightgbm_boosting_model.save_model()\n\n# Calculate the training duration for the LightGBM model\n# This is achieved by subtracting the start time from the current time\nlightgbm_training_duration = time.time() - lightgbm_start_time\n\n# Start timing the XGBoost model training process\nxgboost_start_time = time.time()\n\n# Initialize the XGBoost model\n# This step creates an instance of the XGBoost algorithm for training\nxgboost_boosting_model = XGBoost()\n\n# Train the XGBoost model with the dataset\n# The training process allows the model to learn the patterns within the data\nxgboost_boosting_model.model_training()\n\n# Save the trained XGBoost model to a file\n# Saving the model enables future use without the need for retraining\nxgboost_boosting_model.save_model()\n\n# Calculate the training duration for the XGBoost model\n# The duration is calculated by subtracting the start time from the current time\nxgboost_training_duration = time.time() - xgboost_start_time","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"9d1f62fc-fe9e-4f8f-a548-3dd1a0809f41","outputs":[],"execution_count":24},{"source":"# 5. Neural Network - Artificial Neural Network (ANN)\n\n# Record the start time for training the ANN model\nstart_time = time.time()\n\n# Instantiate the ANN model\nann_network = ANN()\n\n# Train the ANN model\nann_network.model_training()\n\n# Save the trained ANN model using TensorFlow's save method\nann_network.model.save(os.path.join(p.model_path, f'{ann_network.model_name}.h5'))\n\n# Calculate the total training time for the ANN model\nann_training_duration = time.time() - start_time","metadata":{"executionCancelledAt":null,"executionTime":456997,"lastExecutedAt":1716092441905,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 5. Neural Network - Artificial Neural Network (ANN)\n\n# Record the start time for training the ANN model\nstart_time = time.time()\n\n# Instantiate the ANN model\nann_network = ANN()\n\n# Train the ANN model\nann_network.model_training()\n\n# Save the trained ANN model using TensorFlow's save method\nann_network.model.save(os.path.join(p.model_path, f'{ann_network.model_name}.h5'))\n\n# Calculate the total training time for the ANN model\nann_training_duration = time.time() - start_time","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"0a095cab-8f6b-411b-8b3f-29192d5db675","outputs":[],"execution_count":7},{"source":"# 6. Neural Network - Long Short-Term Memory (LSTM)\n\n# Record the start time before training the LSTM model\nstart_time = time.time()\n\n# Instantiate the LSTM model\nlstm_network = LongShortTM()\n\n# Train the LSTM model\nlstm_network.model_training()\n\n# Save the trained ANN model using TensorFlow's save method\nlstm_network.model.save(os.path.join(p.model_path, f'{lstm_network.model_name}.h5'))\n\n# Calculate the total training time for the LSTM model\nlstm_training_duration = time.time() - start_time","cell_type":"code","id":"8be44f07-d575-4183-8509-43e8b02cb3f8","outputs":[],"execution_count":8,"metadata":{"executionCancelledAt":null,"executionTime":1923766,"lastExecutedAt":1716094510678,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 6. Neural Network - Long Short-Term Memory (LSTM)\n\n# Record the start time before training the LSTM model\nstart_time = time.time()\n\n# Instantiate the LSTM model\nlstm_network = LongShortTM()\n\n# Train the LSTM model\nlstm_network.model_training()\n\n# Save the trained ANN model using TensorFlow's save method\nlstm_network.model.save(os.path.join(p.model_path, f'{lstm_network.model_name}.h5'))\n\n# Calculate the total training time for the LSTM model\nlstm_training_duration = time.time() - start_time","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}}},{"source":"# 7. Ensemble of Models\n\n# Train and save the Ensemble Voting model\n\n# Record the start time before training the Ensemble Voting model\nstart_time_voting = time.time()\n\n# Create an instance of the Ensemble Voting model\nensemble_voting = Ensemble_Voting()\n\n# Train the Ensemble Voting model\nensemble_voting.model_training()\n\n# Save the trained Ensemble Voting model\nensemble_voting.save_model()\n\n# Calculate the total training time for the Ensemble Voting model\nvoting_training_duration = time.time() - start_time_voting\n\n# Train and save the Ensemble Stacking model\n\n# Record the start time before training the Ensemble Stacking model\nstart_time_stacking = time.time()\n\n# Create an instance of the Ensemble Stacking model\nensemble_stacking = Ensemble_Stacking()\n\n# Train the Ensemble Stacking model\nensemble_stacking.model_training()\n\n# Save the trained Ensemble Stacking model\nensemble_stacking.save_model()\n\n# Calculate the total training time for the Ensemble Stacking model\nstacking_training_duration = time.time() - start_time_stacking","metadata":{"executionCancelledAt":null,"executionTime":6442914,"lastExecutedAt":1715707323311,"lastExecutedByKernel":"da83825d-af40-40cf-ad37-4c6c50e3ba6c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# 7. Ensemble of Models\n\n# Train and save the Ensemble Voting model\n\n# Record the start time before training the Ensemble Voting model\nstart_time_voting = time.time()\n\n# Create an instance of the Ensemble Voting model\nensemble_voting = Ensemble_Voting()\n\n# Train the Ensemble Voting model\nensemble_voting.model_training()\n\n# Save the trained Ensemble Voting model\nensemble_voting.save_model()\n\n# Calculate the total training time for the Ensemble Voting model\nvoting_training_duration = time.time() - start_time_voting\n\n# Train and save the Ensemble Stacking model\n\n# Record the start time before training the Ensemble Stacking model\nstart_time_stacking = time.time()\n\n# Create an instance of the Ensemble Stacking model\nensemble_stacking = Ensemble_Stacking()\n\n# Train the Ensemble Stacking model\nensemble_stacking.model_training()\n\n# Save the trained Ensemble Stacking model\nensemble_stacking.save_model()\n\n# Calculate the total training time for the Ensemble Stacking model\nstacking_training_duration = time.time() - start_time_stacking","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"991df0bc-dc8c-431e-b286-5caa47420976","outputs":[],"execution_count":27},{"source":"# Print the time taken for each process\nprint(f\"\"\"\nThe time taken (s) for the following processes are noted below:\nETL             : {etl_load_time:.2f}\nLogistic        : {LR_training_duration:.2f}\nARIMA           : {arima_training_duration: .2f}\nRandom Forest   : {random_forest_training_duration:.2f}\nLightGBM        : {lightgbm_training_duration:.2f}\nXGBoost         : {xgboost_training_duration:.2f}\nANN             : {ann_training_duration:.2f}\nLSTM            : {lstm_training_duration:.2f}\nVoting          : {voting_training_duration:.2f}\nStacking        : {stacking_training_duration:.2f}\n\"\"\")","metadata":{"executionCancelledAt":null,"executionTime":16,"lastExecutedAt":1715707427384,"lastExecutedByKernel":"da83825d-af40-40cf-ad37-4c6c50e3ba6c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print the time taken for each process\nprint(f\"\"\"\nThe time taken (s) for the following processes are noted below:\nETL             : {etl_load_time:.2f}\nLogistic        : {LR_training_duration:.2f}\nARIMA           : {arima_training_duration: .2f}\nRandom Forest   : {random_forest_training_duration:.2f}\nLightGBM        : {lightgbm_training_duration:.2f}\nXGBoost         : {xgboost_training_duration:.2f}\nANN             : {ann_training_duration:.2f}\nLSTM            : {lstm_training_duration:.2f}\nVoting          : {voting_training_duration:.2f}\nStacking        : {stacking_training_duration:.2f}\n\"\"\")","outputsMetadata":{"0":{"height":290,"type":"stream"}}},"cell_type":"code","id":"cd7f43d5-6351-4106-a68c-cdfb1ff05d96","outputs":[],"execution_count":28},{"source":"# Initialize and evaluate the Logistic Regression model, then backtest its trading strategy\nlogistic_regression_model = Logistic_Regression()\nlogistic_regression_model.model_evaluation()  # Evaluate the Logistic Regression model's performance\nlogistic_regression_model.backtest_strategy()  # Backtest the trading strategy based on the Logistic Regression model\n\n# Initialize and evaluate the ARIMA model, then backtest its trading strategy\narima_model_instance = ARIMA()\narima_model_instance.model_evaluation()  # Evaluate the ARIMA model's forecasting accuracy\narima_model_instance.backtest_strategy()  # Backtest the trading strategy based on the ARIMA model predictions\n\n# Initialize and evaluate the Random Forest model, then backtest its trading strategy\nrandom_forest_model = RandomForest()\nrandom_forest_model.model_evaluation()  # Evaluate the Random Forest model's classification or regression performance\nrandom_forest_model.backtest_strategy()  # Backtest the trading strategy based on the Random Forest model\n\n# Initialize and evaluate the LightGBM model, then backtest its trading strategy\nlightgbm_model_instance = LightGBM()\nlightgbm_model_instance.model_evaluation()  # Evaluate the LightGBM model's performance\nlightgbm_model_instance.backtest_strategy()  # Backtest the trading strategy based on the LightGBM model\n\n# Initialize and evaluate the XGBoost model, then backtest its trading strategy\nxgboost_model_instance = XGBoost()\nxgboost_model_instance.model_evaluation()  # Evaluate the XGBoost model's performance\nxgboost_model_instance.backtest_strategy()  # Backtest the trading strategy based on the XGBoost model\n\n# Initialize and evaluate the ANN (Artificial Neural Network) model, then backtest its trading strategy\nann_model_instance = ANN()\nann_model_instance.model_evaluation()  # Evaluate the ANN model's performance\nann_model_instance.backtest_strategy()  # Backtest the trading strategy based on the ANN model\n\n# Initialize and evaluate the LSTM (Long Short-Term Memory) model, then backtest its trading strategy\nlstm_model_instance = LongShortTM()\nlstm_model_instance.model_evaluation()  # Evaluate the LSTM model's performance\nlstm_model_instance.backtest_strategy()  # Backtest the trading strategy based on the LSTM model\n\n# Initialize and evaluate the Ensemble Voting model, then backtest its trading strategy\nvoting_ensemble_model = Ensemble_Voting()\nvoting_ensemble_model.model_evaluation()  # Evaluate the Ensemble Voting model's performance\nvoting_ensemble_model.backtest_strategy()  # Backtest the trading strategy based on the Ensemble Voting model\n\n# Initialize and evaluate the Ensemble Stacking model, then backtest its trading strategy\nstacking_ensemble_model = Ensemble_Stacking()\nstacking_ensemble_model.model_evaluation()  # Evaluate the Ensemble Stacking model's performance\nstacking_ensemble_model.backtest_strategy()  # Backtest the trading strategy based on the Ensemble Stacking model\n\n# Compile and review all model evaluation reports to compare performance and select the best model\ncompile_model_eval_reports()  # Compile model evaluation reports for all models","metadata":{"executionCancelledAt":null,"executionTime":4233,"lastExecutedAt":1716100381731,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize and evaluate the Logistic Regression model, then backtest its trading strategy\nlogistic_regression_model = Logistic_Regression()\nlogistic_regression_model.model_evaluation()  # Evaluate the Logistic Regression model's performance\nlogistic_regression_model.backtest_strategy()  # Backtest the trading strategy based on the Logistic Regression model\n\n# Initialize and evaluate the ARIMA model, then backtest its trading strategy\narima_model_instance = ARIMA()\narima_model_instance.model_evaluation()  # Evaluate the ARIMA model's forecasting accuracy\narima_model_instance.backtest_strategy()  # Backtest the trading strategy based on the ARIMA model predictions\n\n# Initialize and evaluate the Random Forest model, then backtest its trading strategy\nrandom_forest_model = RandomForest()\nrandom_forest_model.model_evaluation()  # Evaluate the Random Forest model's classification or regression performance\nrandom_forest_model.backtest_strategy()  # Backtest the trading strategy based on the Random Forest model\n\n# Initialize and evaluate the LightGBM model, then backtest its trading strategy\nlightgbm_model_instance = LightGBM()\nlightgbm_model_instance.model_evaluation()  # Evaluate the LightGBM model's performance\nlightgbm_model_instance.backtest_strategy()  # Backtest the trading strategy based on the LightGBM model\n\n# Initialize and evaluate the XGBoost model, then backtest its trading strategy\nxgboost_model_instance = XGBoost()\nxgboost_model_instance.model_evaluation()  # Evaluate the XGBoost model's performance\nxgboost_model_instance.backtest_strategy()  # Backtest the trading strategy based on the XGBoost model\n\n# Initialize and evaluate the ANN (Artificial Neural Network) model, then backtest its trading strategy\nann_model_instance = ANN()\nann_model_instance.model_evaluation()  # Evaluate the ANN model's performance\nann_model_instance.backtest_strategy()  # Backtest the trading strategy based on the ANN model\n\n# Initialize and evaluate the LSTM (Long Short-Term Memory) model, then backtest its trading strategy\nlstm_model_instance = LongShortTM()\nlstm_model_instance.model_evaluation()  # Evaluate the LSTM model's performance\nlstm_model_instance.backtest_strategy()  # Backtest the trading strategy based on the LSTM model\n\n# Initialize and evaluate the Ensemble Voting model, then backtest its trading strategy\nvoting_ensemble_model = Ensemble_Voting()\nvoting_ensemble_model.model_evaluation()  # Evaluate the Ensemble Voting model's performance\nvoting_ensemble_model.backtest_strategy()  # Backtest the trading strategy based on the Ensemble Voting model\n\n# Initialize and evaluate the Ensemble Stacking model, then backtest its trading strategy\nstacking_ensemble_model = Ensemble_Stacking()\nstacking_ensemble_model.model_evaluation()  # Evaluate the Ensemble Stacking model's performance\nstacking_ensemble_model.backtest_strategy()  # Backtest the trading strategy based on the Ensemble Stacking model\n\n# Compile and review all model evaluation reports to compare performance and select the best model\ncompile_model_eval_reports()  # Compile model evaluation reports for all models","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"75a36c81-72fb-41b2-905a-140f2c2482ae","outputs":[],"execution_count":5},{"source":"# Instantiate and evaluate various financial models, then backtest their strategies under stress conditions\n\n# Instantiate the Logistic Regression model\nlogistic_regression_model = Logistic_Regression()\n# Evaluate the Logistic Regression model under stress backtest scenario\nlogistic_regression_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Logistic Regression model under stress conditions\nlogistic_regression_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Random Forest model\nrandom_forest_model = RandomForest()\n# Evaluate the Random Forest model under stress backtest conditions\nrandom_forest_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Random Forest model under stress conditions\nrandom_forest_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the LightGBM classifier model\nlightgbm_classifier_model = LightGBM()\n# Evaluate the LightGBM model under stress backtest conditions\nlightgbm_classifier_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the LightGBM model under stress conditions\nlightgbm_classifier_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the XGBoost classifier model\nxgboost_classifier_model = XGBoost()\n# Evaluate the XGBoost model under stress backtest conditions\nxgboost_classifier_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the XGBoost model under stress conditions\nxgboost_classifier_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Artificial Neural Network (ANN) model\nartificial_neural_network_model = ANN()\n# Evaluate the ANN model under stress backtest conditions\nartificial_neural_network_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the ANN model under stress conditions\nartificial_neural_network_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Long Short-Term Memory (LSTM) network model\nlstm_network_model = LongShortTM()\n# Evaluate the LSTM model under stress backtest conditions\nlstm_network_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the LSTM model under stress conditions\nlstm_network_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Ensemble Voting classifier model\nensemble_voting_classifier = Ensemble_Voting()\n# Evaluate the Ensemble Voting model under stress backtest conditions\nensemble_voting_classifier.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Ensemble Voting model under stress conditions\nensemble_voting_classifier.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Ensemble Stacking classifier model\nensemble_stacking_classifier = Ensemble_Stacking()\n# Evaluate the Ensemble Stacking model under stress backtest conditions\nensemble_stacking_classifier.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Ensemble Stacking model under stress conditions\nensemble_stacking_classifier.backtest_strategy(backtest=\"stress\")\n\n# Compile and generate evaluation reports for all models to compare their performance\ncompile_model_eval_reports()","metadata":{"executionCancelledAt":null,"executionTime":3985,"lastExecutedAt":1716101151513,"lastExecutedByKernel":"413c4cad-ca5d-4424-aeb9-3017cf19ff1a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate and evaluate various financial models, then backtest their strategies under stress conditions\n\n# Instantiate the Logistic Regression model\nlogistic_regression_model = Logistic_Regression()\n# Evaluate the Logistic Regression model under stress backtest scenario\nlogistic_regression_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Logistic Regression model under stress conditions\nlogistic_regression_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Random Forest model\nrandom_forest_model = RandomForest()\n# Evaluate the Random Forest model under stress backtest conditions\nrandom_forest_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Random Forest model under stress conditions\nrandom_forest_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the LightGBM classifier model\nlightgbm_classifier_model = LightGBM()\n# Evaluate the LightGBM model under stress backtest conditions\nlightgbm_classifier_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the LightGBM model under stress conditions\nlightgbm_classifier_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the XGBoost classifier model\nxgboost_classifier_model = XGBoost()\n# Evaluate the XGBoost model under stress backtest conditions\nxgboost_classifier_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the XGBoost model under stress conditions\nxgboost_classifier_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Artificial Neural Network (ANN) model\nartificial_neural_network_model = ANN()\n# Evaluate the ANN model under stress backtest conditions\nartificial_neural_network_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the ANN model under stress conditions\nartificial_neural_network_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Long Short-Term Memory (LSTM) network model\nlstm_network_model = LongShortTM()\n# Evaluate the LSTM model under stress backtest conditions\nlstm_network_model.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the LSTM model under stress conditions\nlstm_network_model.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Ensemble Voting classifier model\nensemble_voting_classifier = Ensemble_Voting()\n# Evaluate the Ensemble Voting model under stress backtest conditions\nensemble_voting_classifier.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Ensemble Voting model under stress conditions\nensemble_voting_classifier.backtest_strategy(backtest=\"stress\")\n\n# Instantiate the Ensemble Stacking classifier model\nensemble_stacking_classifier = Ensemble_Stacking()\n# Evaluate the Ensemble Stacking model under stress backtest conditions\nensemble_stacking_classifier.model_evaluation(backtest=\"stress\")\n# Backtest the trading strategy based on the Ensemble Stacking model under stress conditions\nensemble_stacking_classifier.backtest_strategy(backtest=\"stress\")\n\n# Compile and generate evaluation reports for all models to compare their performance\ncompile_model_eval_reports()","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"346f55c6-4427-4037-925a-5eb1027fb8b1","outputs":[],"execution_count":4},{"source":"# Measure the execution time for each model's SHAP value generation\n\n# Logistic Regression\nstart_time_logistic = time.time()  # Start the timer for Logistic Regression\nlogistic_regression_model = Logistic_Regression()  # Instantiate the Logistic Regression model\nlogistic_regression_model.generate_shap_value()  # Generate SHAP values for Logistic Regression\nlogistic_regression_shap_time = time.time() - start_time_logistic  # Calculate the execution time for Logistic Regression\n\n# Random Forest\nstart_time_rf = time.time()  # Start the timer for Random Forest\nrandom_forest_model = RandomForest()  # Instantiate the Random Forest model\nrandom_forest_model.generate_shap_value()  # Generate SHAP values for Random Forest\nrandom_forest_shap_time = time.time() - start_time_rf  # Calculate the execution time for Random Forest","metadata":{"executionCancelledAt":null,"executionTime":138527,"lastExecutedAt":1716114851153,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Measure the execution time for each model's SHAP value generation\n\n# Logistic Regression\nstart_time_logistic = time.time()  # Start the timer for Logistic Regression\nlogistic_regression_model = Logistic_Regression()  # Instantiate the Logistic Regression model\nlogistic_regression_model.generate_shap_value()  # Generate SHAP values for Logistic Regression\nlogistic_regression_shap_time = time.time() - start_time_logistic  # Calculate the execution time for Logistic Regression\n\n# Random Forest\nstart_time_rf = time.time()  # Start the timer for Random Forest\nrandom_forest_model = RandomForest()  # Instantiate the Random Forest model\nrandom_forest_model.generate_shap_value()  # Generate SHAP values for Random Forest\nrandom_forest_shap_time = time.time() - start_time_rf  # Calculate the execution time for Random Forest","outputsMetadata":{"0":{"height":59,"type":"stream"},"1":{"height":616,"type":"stream"},"2":{"height":38,"type":"stream"},"3":{"height":416,"type":"stream"},"4":{"height":38,"type":"stream"},"5":{"height":185,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"9ebd8486-f944-47c8-8147-260aa63a2415","outputs":[],"execution_count":4},{"source":"# LightGBM\nstart_time_lgbm = time.time()  # Start the timer for LightGBM\nlightgbm_model = LightGBM()  # Instantiate the LightGBM model\nlightgbm_model.generate_shap_value()  # Generate SHAP values for LightGBM\nlightgbm_shap_time = time.time() - start_time_lgbm  # Calculate the execution time for LightGBM","metadata":{"executionCancelledAt":null,"executionTime":53405,"lastExecutedAt":1716114914266,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# LightGBM\nstart_time_lgbm = time.time()  # Start the timer for LightGBM\nlightgbm_model = LightGBM()  # Instantiate the LightGBM model\nlightgbm_model.generate_shap_value()  # Generate SHAP values for LightGBM\nlightgbm_shap_time = time.time() - start_time_lgbm  # Calculate the execution time for LightGBM","outputsMetadata":{"0":{"height":38,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"1a353eb4-69c8-4506-b8be-ddc53a315af1","outputs":[],"execution_count":5},{"source":"# XGBoost\nstart_time_xgb = time.time()  # Start the timer for XGBoost\nxgboost_model = XGBoost()  # Instantiate the XGBoost model\nxgboost_model.generate_shap_value()  # Generate SHAP values for XGBoost\nxgboost_shap_time = time.time() - start_time_xgb  # Calculate the execution time for XGBoost","metadata":{"executionCancelledAt":null,"executionTime":39911,"lastExecutedAt":1716114967133,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# XGBoost\nstart_time_xgb = time.time()  # Start the timer for XGBoost\nxgboost_model = XGBoost()  # Instantiate the XGBoost model\nxgboost_model.generate_shap_value()  # Generate SHAP values for XGBoost\nxgboost_shap_time = time.time() - start_time_xgb  # Calculate the execution time for XGBoost","outputsMetadata":{"0":{"height":38,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"8f2cbf81-5e2d-4ca1-844c-cf79c599582a","outputs":[],"execution_count":6},{"source":"# Ensemble Voting\nstart_time_voting = time.time()  # Start the timer for Ensemble Voting\nensemble_voting_model = Ensemble_Voting()  # Instantiate the Ensemble Voting model\nensemble_voting_model.generate_shap_value()  # Generate SHAP values for Ensemble Voting\nvoting_shap_time = time.time() - start_time_voting  # Calculate the execution time for Ensemble Voting","metadata":{"executionCancelledAt":null,"executionTime":3343482,"lastExecutedAt":1716118318784,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Ensemble Voting\nstart_time_voting = time.time()  # Start the timer for Ensemble Voting\nensemble_voting_model = Ensemble_Voting()  # Instantiate the Ensemble Voting model\nensemble_voting_model.generate_shap_value()  # Generate SHAP values for Ensemble Voting\nvoting_shap_time = time.time() - start_time_voting  # Calculate the execution time for Ensemble Voting","outputsMetadata":{"0":{"height":38,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"4b36ee32-b19f-4f84-9ba5-58b26dec0320","outputs":[],"execution_count":7},{"source":"# Ensemble Stacking\nstart_time_stacking = time.time()  # Start the timer for Ensemble Stacking\nensemble_stacking_model = Ensemble_Stacking()  # Instantiate the Ensemble Stacking model\nensemble_stacking_model.generate_shap_value()  # Generate SHAP values for Ensemble Stacking\nstacking_shap_time = time.time() - start_time_stacking  # Calculate the execution time for Ensemble Stacking","metadata":{"executionCancelledAt":null,"executionTime":3563054,"lastExecutedAt":1716121887300,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Ensemble Stacking\nstart_time_stacking = time.time()  # Start the timer for Ensemble Stacking\nensemble_stacking_model = Ensemble_Stacking()  # Instantiate the Ensemble Stacking model\nensemble_stacking_model.generate_shap_value()  # Generate SHAP values for Ensemble Stacking\nstacking_shap_time = time.time() - start_time_stacking  # Calculate the execution time for Ensemble Stacking","outputsMetadata":{"0":{"height":38,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"1deaa05b-c0ef-4944-b3de-ad77c967e695","outputs":[],"execution_count":8},{"source":"%%capture\n\n# ANN (Artificial Neural Network)\nstart_time_ann = time.time()  # Start the timer for ANN\nann_model = ANN()  # Instantiate the ANN model\nann_model.generate_shap_value()  # Generate SHAP values for ANN\nann_shap_time = time.time() - start_time_ann  # Calculate the execution time for ANN","metadata":{"executionCancelledAt":null,"executionTime":5402947,"lastExecutedAt":1716132682624,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%capture\n\n# ANN (Artificial Neural Network)\nstart_time_ann = time.time()  # Start the timer for ANN\nann_model = ANN()  # Instantiate the ANN model\nann_model.generate_shap_value()  # Generate SHAP values for ANN\nann_shap_time = time.time() - start_time_ann  # Calculate the execution time for ANN","outputsMetadata":{"0":{"height":416,"type":"stream"},"1":{"height":38,"type":"stream"},"2":{"height":416,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":416,"type":"stream"},"5":{"height":38,"type":"stream"},"6":{"height":416,"type":"stream"},"7":{"height":38,"type":"stream"},"8":{"height":416,"type":"stream"},"9":{"height":38,"type":"stream"},"10":{"height":416,"type":"stream"},"11":{"height":38,"type":"stream"},"12":{"height":416,"type":"stream"},"13":{"height":38,"type":"stream"},"14":{"height":416,"type":"stream"},"15":{"height":38,"type":"stream"},"16":{"height":416,"type":"stream"},"17":{"height":38,"type":"stream"},"18":{"height":416,"type":"stream"},"19":{"height":38,"type":"stream"},"20":{"height":416,"type":"stream"},"21":{"height":38,"type":"stream"},"22":{"height":416,"type":"stream"},"23":{"height":38,"type":"stream"},"24":{"height":416,"type":"stream"},"25":{"height":38,"type":"stream"},"26":{"height":416,"type":"stream"},"27":{"height":38,"type":"stream"},"28":{"height":416,"type":"stream"},"29":{"height":38,"type":"stream"},"30":{"height":416,"type":"stream"},"31":{"height":38,"type":"stream"},"32":{"height":416,"type":"stream"},"33":{"height":38,"type":"stream"},"34":{"height":416,"type":"stream"},"35":{"height":38,"type":"stream"},"36":{"height":416,"type":"stream"},"37":{"height":38,"type":"stream"},"38":{"height":416,"type":"stream"},"39":{"height":38,"type":"stream"},"40":{"height":416,"type":"stream"},"41":{"height":38,"type":"stream"},"42":{"height":416,"type":"stream"},"43":{"height":38,"type":"stream"},"44":{"height":416,"type":"stream"},"45":{"height":38,"type":"stream"},"46":{"height":416,"type":"stream"},"47":{"height":38,"type":"stream"},"48":{"height":416,"type":"stream"},"49":{"height":38,"type":"stream"},"50":{"height":416,"type":"stream"},"51":{"height":38,"type":"stream"},"52":{"height":416,"type":"stream"},"53":{"height":38,"type":"stream"},"54":{"height":416,"type":"stream"},"55":{"height":38,"type":"stream"},"56":{"height":416,"type":"stream"},"57":{"height":38,"type":"stream"},"58":{"height":416,"type":"stream"},"59":{"height":38,"type":"stream"},"60":{"height":416,"type":"stream"},"61":{"height":38,"type":"stream"},"62":{"height":416,"type":"stream"},"63":{"height":38,"type":"stream"},"64":{"height":416,"type":"stream"},"65":{"height":38,"type":"stream"},"66":{"height":416,"type":"stream"},"67":{"height":38,"type":"stream"},"68":{"height":416,"type":"stream"},"69":{"height":38,"type":"stream"},"70":{"height":416,"type":"stream"},"71":{"height":38,"type":"stream"},"72":{"height":416,"type":"stream"},"73":{"height":38,"type":"stream"},"74":{"height":416,"type":"stream"},"75":{"height":38,"type":"stream"},"76":{"height":416,"type":"stream"},"77":{"height":38,"type":"stream"},"78":{"height":416,"type":"stream"},"79":{"height":38,"type":"stream"},"80":{"height":416,"type":"stream"},"81":{"height":38,"type":"stream"},"82":{"height":416,"type":"stream"},"83":{"height":38,"type":"stream"},"84":{"height":416,"type":"stream"},"85":{"height":38,"type":"stream"},"86":{"height":416,"type":"stream"},"87":{"height":38,"type":"stream"},"88":{"height":416,"type":"stream"},"89":{"height":38,"type":"stream"},"90":{"height":416,"type":"stream"},"91":{"height":38,"type":"stream"},"92":{"height":416,"type":"stream"},"93":{"height":38,"type":"stream"},"94":{"height":416,"type":"stream"},"95":{"height":38,"type":"stream"},"96":{"height":416,"type":"stream"},"97":{"height":38,"type":"stream"},"98":{"height":416,"type":"stream"},"99":{"height":38,"type":"stream"},"100":{"height":416,"type":"stream"},"101":{"height":38,"type":"stream"},"102":{"height":416,"type":"stream"},"103":{"height":38,"type":"stream"},"104":{"height":416,"type":"stream"},"105":{"height":38,"type":"stream"},"106":{"height":416,"type":"stream"},"107":{"height":38,"type":"stream"},"108":{"height":416,"type":"stream"},"109":{"height":38,"type":"stream"},"110":{"height":416,"type":"stream"},"111":{"height":38,"type":"stream"},"112":{"height":416,"type":"stream"},"113":{"height":38,"type":"stream"},"114":{"height":416,"type":"stream"},"115":{"height":38,"type":"stream"},"116":{"height":416,"type":"stream"},"117":{"height":38,"type":"stream"},"118":{"height":416,"type":"stream"},"119":{"height":38,"type":"stream"},"120":{"height":416,"type":"stream"},"121":{"height":38,"type":"stream"},"122":{"height":416,"type":"stream"},"123":{"height":38,"type":"stream"},"124":{"height":416,"type":"stream"},"125":{"height":38,"type":"stream"},"126":{"height":416,"type":"stream"},"127":{"height":38,"type":"stream"},"128":{"height":416,"type":"stream"},"129":{"height":38,"type":"stream"},"130":{"height":416,"type":"stream"},"131":{"height":38,"type":"stream"},"132":{"height":416,"type":"stream"},"133":{"height":38,"type":"stream"},"134":{"height":416,"type":"stream"},"135":{"height":38,"type":"stream"},"136":{"height":416,"type":"stream"},"137":{"height":38,"type":"stream"},"138":{"height":416,"type":"stream"},"139":{"height":38,"type":"stream"},"140":{"height":416,"type":"stream"},"141":{"height":38,"type":"stream"},"142":{"height":416,"type":"stream"},"143":{"height":38,"type":"stream"},"144":{"height":416,"type":"stream"},"145":{"height":38,"type":"stream"},"146":{"height":101,"type":"stream"},"147":{"height":38,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"d89b23fd-ac1c-4f88-9e96-35319803924a","outputs":[],"execution_count":5},{"source":"%%capture\n\n# LSTM (Long Short-Term Memory)\nstart_time_lstm = time.time()  # Start the timer for LSTM\nlstm_model = LongShortTM()  # Instantiate the LSTM model\nlstm_model.generate_shap_value()  # Generate SHAP values for LSTM\nlstm_shap_time = time.time() - start_time_lstm  # Calculate the execution time for LSTM","metadata":{"executionCancelledAt":null,"executionTime":28450233,"lastExecutedAt":1716161790669,"lastExecutedByKernel":"ae88924d-9bbb-44bc-aad0-c11de5a3cba9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%capture\n\n# LSTM (Long Short-Term Memory)\nstart_time_lstm = time.time()  # Start the timer for LSTM\nlstm_model = LongShortTM()  # Instantiate the LSTM model\nlstm_model.generate_shap_value()  # Generate SHAP values for LSTM\nlstm_shap_time = time.time() - start_time_lstm  # Calculate the execution time for LSTM"},"cell_type":"code","id":"1f74a6a6-8f65-4a26-b148-f68c7b6b3af5","outputs":[],"execution_count":6}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}